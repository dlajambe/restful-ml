"""This file contains endpoints that allow predictions to be obtained
from different types of models with a URL. 
"""
import logging
from flask_restful import Resource, reqparse
from modules.data_preprocessing import LanguagePreprocessor
from modules.data_preprocessing import NumericalPreprocessor
from modules.models import LanguageModel, NumericalModel

# Loading models and preprocessors can be expensive, so they are
# initialized outside the endpoint controllers to ensure that they are
# only loaded once
language_model = LanguageModel()
numerical_model = NumericalModel()

language_preprocessor = LanguagePreprocessor()
numerical_preprocessor = NumericalPreprocessor()

OK = 200
BAD_REQUEST = 400

# TODO: Put duplicated POST request code in a common function that can
# be called by any resource
def generate_prediction(model):
    pass

class StringPrediction(Resource):
    """Handles requests for string-based model predictions at the
    /string-prediction endpoint.

    This resource is intended to be used for models that receive input
    data in string format, i.e. language models. The input string must
    be received in JSON format with 'input_data' as the key and a string
    as the value.

    Example input JSON: {"input_data" : "When Harry met"}

    The prediction generated by the model is returned in JSON format
    with 'prediction' as the key.

    Example response JSON: {"prediction" : "Sally"}
    """
    req_parser = reqparse.RequestParser()
    req_parser.add_argument(
        'input_data', type=str, location='json',
        help=('Input JSON must follow this format: '
              '{"input_data": "example_str"}'),
        required=True)
    endpoint_suffix = '/string-prediction'
    
    def post(self) -> dict:
        logging.info(
            'Processing incoming POST request for {}'.
            format(StringPrediction.endpoint_suffix))
        try:
            args = StringPrediction.req_parser.parse_args()
            logging.info('\tArguments parsed: {}'.format(args))
        except:
            error_type = 'Bad request'
            error_msg = (
                'The input data could not be parsed - verify JSON format')
            response = {
                'error': error_type,
                'message': error_msg}
            logging.error(
                '\t{} ({}): {}'.format(error_type, BAD_REQUEST, error_msg))
            return response, BAD_REQUEST
        input_data_raw = args['input_data']
        input_data = language_preprocessor.preprocess_data(input_data_raw)
        output = language_model.predict(input_data)
        logging.info('\tPrediction generated: {}'.format(output))
        response = {'prediction': output}
        return response, OK
    
class FloatPrediction(Resource):
    """Generate a single prediction from a machine learning model at the
    /float-prediction endpoint.

    This resource is intended to be used for models that receive input
    data as a vector of floating point data, e.g. time series models.
    The input data must be received in JSON format with 'input_data'
    as the key and an array of numbers as the value.

    Example input JSON: {"input_data" : [10.18, 3.33, 7.43]}

    The prediction generated by the model is returned in JSON format
    with 'prediction' as the key.

    Example response JSON: {"prediction" : 3.14}
    """
    req_parser = reqparse.RequestParser()
    req_parser.add_argument(
        'input_data', type=float, action='append', location='json', 
        help=('Input JSON must follow this format: '
              '{"input_data": [3.14, 2.55, ...]}'),
        required=True)
    endpoint_suffix = '/float-prediction'
    
    def post(self) -> dict:
        logging.info(
            'Processing incoming POST request for {}'.
            format(FloatPrediction.endpoint_suffix))
        try:
            args = FloatPrediction.req_parser.parse_args()
            logging.info('\tArguments parsed: {}'.format(args))
        except:
            error_type = 'Bad request'
            error_msg = (
                'The input data could not be parsed - verify JSON format')
            response = {
                'error': error_type,
                'message': error_msg}
            logging.error(
                '\t{} ({}): {}'.format(error_type, BAD_REQUEST, error_msg))
            return response, BAD_REQUEST
        input_data_raw = args['input_data']
        input_data = numerical_preprocessor.preprocess_data(input_data_raw)
        output = numerical_model.predict(input_data)
        logging.info('\tPrediction generated: {}'.format(output))
        response = {'prediction': output}
        return response, OK